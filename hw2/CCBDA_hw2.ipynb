{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d4bc3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "# Device configuration\n",
    "torch.cuda.set_device(0)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3a674c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockPrediction:\n",
    "    def __init__(self,filename):\n",
    "        # read spcific company file\n",
    "        file = open(filename)\n",
    "        rows = csv.reader(file)\n",
    "        next(rows) # remove header\n",
    "        dataset = []\n",
    "        for row in rows:\n",
    "            dataset.append(row)\n",
    "        self.dataset = np.array(dataset)\n",
    "        file.close()\n",
    "        # read Nasdaq index\n",
    "#         file = open('nasdaq.csv')\n",
    "#         rows = csv.reader(file)\n",
    "#         next(rows) # remove header\n",
    "#         nasdaq_data = []\n",
    "#         for row in rows:\n",
    "#             nasdaq_data.append(row)\n",
    "#         self.nasdaq_data = np.array(nasdaq_data)\n",
    "#         file.close()\n",
    "        #print(\"Data number:\",len(dataset))\n",
    "        #print(\"Data number2:\",len(nasdaq_data))\n",
    "    def getFeatures(self):\n",
    "        single_day_features = self.dataset[:,1:]\n",
    "        #single_day_features = np.append(single_day_features,self.nasdaq_data[:,5].reshape(len(self.nasdaq_data[:,5]),1),axis = 1)\n",
    "        single_day_features =  single_day_features.astype(np.double)\n",
    "        # Normalization\n",
    "        for i in range(NUM_FEATURES):\n",
    "            single_day_features[:,i] = (single_day_features[:,i] - np.min(single_day_features[:,i])) / (np.max(single_day_features[:,i])-np.min(single_day_features[:,i]))\n",
    "        # get features\n",
    "        self.features = []\n",
    "        for i in range(len(self.dataset)-SEQ_LENGTH+1):\n",
    "            self.features.append(single_day_features[i:i+SEQ_LENGTH].reshape(NUM_FEATURES*SEQ_LENGTH))\n",
    "        \n",
    "        self.features = np.array(self.features)\n",
    "        self.predict_feature = self.features[-1,:]\n",
    "        self.features = self.features[:-1,:]\n",
    "    def getLabels(self):\n",
    "        self.labels = self.dataset[SEQ_LENGTH:,5]\n",
    "        self.labels = self.labels.astype(np.double)\n",
    "        # normalization\n",
    "        self.label_max = np.max(self.labels)\n",
    "        self.label_min = np.min(self.labels)\n",
    "        self.labels = (self.labels - np.min(self.labels))/(np.max(self.labels)-np.min(self.labels))\n",
    "#     def getLabels(self):\n",
    "#         adj_close = self.dataset[SEQ_LENGTH-1:,5]\n",
    "#         adj_close = adj_close.astype(np.double)\n",
    "#         self.labels = []\n",
    "#         for i in range(1,len(adj_close)):\n",
    "#             if((abs(adj_close[i]-adj_close[i-1])/adj_close[i-1]) > 0.015):\n",
    "#                 if(adj_close[i] > adj_close[i-1]):\n",
    "#                     self.labels.append(0)\n",
    "#                 else:\n",
    "#                     self.labels.append(2)\n",
    "#             else:\n",
    "#                 self.labels.append(1)\n",
    "#         self.labels = np.array(self.labels)\n",
    "#         self.labels = self.labels.astype(np.long)\n",
    "\n",
    "    def shuffleData(self):\n",
    "        data = np.append(self.features,self.labels.reshape(len(self.labels),1),axis=1)\n",
    "        np.random.shuffle(data[:-TEST_SIZE])\n",
    "        #np.random.shuffle(data[:])\n",
    "        self.features = data[:,:NUM_FEATURES*SEQ_LENGTH]\n",
    "        self.labels = data[:,NUM_FEATURES*SEQ_LENGTH]\n",
    "    def splitTrainTest(self,test_size):\n",
    "        self.train_features = self.features[:-test_size]\n",
    "        self.test_features = self.features[-test_size:]\n",
    "        self.train_labels = self.labels[:-test_size]\n",
    "        self.test_labels = self.labels[-test_size:]\n",
    "    def toTensor(self):\n",
    "        self.train_features_ts = torch.from_numpy(self.train_features)\n",
    "        self.test_features_ts = torch.from_numpy(self.test_features)\n",
    "        self.train_labels_ts = torch.from_numpy(self.train_labels)\n",
    "        self.test_labels_ts = torch.from_numpy(self.test_labels)\n",
    "#         print(self.train_features_ts.shape)\n",
    "#         print(self.train_labels_ts.shape)\n",
    "    def train(self):\n",
    "        self.model = LSTM(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS)\n",
    "        self.model = self.model.cuda()\n",
    "        \n",
    "        # Loss and optimizer\n",
    "        loss_func = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=LEARNING_RATE)\n",
    "        \n",
    "        # Prepare data loader\n",
    "        train_dataset = torch.utils.data.TensorDataset(self.train_features_ts,self.train_labels_ts)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        test_dataset = torch.utils.data.TensorDataset(self.test_features_ts,self.test_labels_ts)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=TEST_SIZE, shuffle=False)\n",
    "        \n",
    "       \n",
    "        self.train_loss_list = []\n",
    "        self.test_loss_list = []\n",
    "        train_loss = 0\n",
    "        for ep in range(NUM_EPOCHS):\n",
    "            # Train the model\n",
    "            for i, (data, labels) in enumerate(train_loader):\n",
    "                # resize\n",
    "                data = Variable(data.view(-1, SEQ_LENGTH, INPUT_SIZE).float().cuda())\n",
    "                labels = Variable(labels.view(len(labels),1).float().cuda())\n",
    "                \n",
    "                # forward pass\n",
    "                outputs = self.model(data)\n",
    "                train_loss = loss_func(outputs,labels)\n",
    "                \n",
    "                # backward and optimize\n",
    "                optimizer.zero_grad() # clear gradient\n",
    "                train_loss.backward() # backpropagation to get gradient\n",
    "                optimizer.step() # optimize parameters\n",
    "                \n",
    "                # output result\n",
    "                #print('Epoch:',ep+1,', Step:',i+1,', Loss:', train_loss.item())\n",
    "                \n",
    "            self.train_loss_list.append(train_loss.item())\n",
    "            \n",
    "            # Test the model\n",
    "            test_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for data , labels in test_loader:\n",
    "                    # resize\n",
    "                    data = data.view(-1, SEQ_LENGTH, INPUT_SIZE).float().cuda()\n",
    "                    labels = labels.view(len(labels),1).float().cuda()\n",
    "\n",
    "                    # forward pass\n",
    "                    outputs = self.model(data)\n",
    "                    test_loss = loss_func(outputs,labels)\n",
    "\n",
    "                    # record loss\n",
    "                    self.test_loss_list.append(test_loss.cpu().item())\n",
    "    def test(self):\n",
    "        # Prepare data loader\n",
    "        test_dataset = torch.utils.data.TensorDataset(self.test_features_ts,self.test_labels_ts)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "        \n",
    "        # Test the model\n",
    "        # In test phase, we don't need to compute gradients (for memory efficient)\n",
    "        with torch.no_grad():\n",
    "            n_correct = 0\n",
    "            n_samples = 0\n",
    "            for data , labels in test_loader:\n",
    "                # resize\n",
    "                data = data.view(-1, SEQ_LENGTH, INPUT_SIZE).cuda()\n",
    "                labels = labels.float().cpu()\n",
    "                # Forward pass\n",
    "                outputs = self.model(data.float())\n",
    "                \n",
    "                # calculate reuslt\n",
    "                n_samples += labels.size(0)\n",
    "                labels = labels.item()\n",
    "                if(abs(outputs.cpu().item()-labels)/(labels+0.00000001) < 0.015):\n",
    "                    n_correct += 1\n",
    "                #print(outputs.cpu().item(),labels)\n",
    "            accuracy = 100.0 * n_correct / n_samples\n",
    "            print(\"Accuracy(in +- 1.5%):\",accuracy,\"%\")\n",
    "    def predict(self):\n",
    "        \n",
    "        # get output\n",
    "        with torch.no_grad():\n",
    "            #print(self.predict_feature)\n",
    "            data = torch.from_numpy(self.predict_feature).cuda()\n",
    "            # resize\n",
    "            data = data.view(-1, SEQ_LENGTH, INPUT_SIZE)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = self.model(data.float())\n",
    "            output = output*(self.label_max-self.label_min)+self.label_min\n",
    "            output = output.item()\n",
    "            past = self.labels[-1]\n",
    "            past = past *(self.label_max-self.label_min)+self.label_min\n",
    "            print(output,past,end=', ')\n",
    "            if(abs(output-past)/past > 0.015):\n",
    "                if(output > past):\n",
    "                    ans = 0\n",
    "                else:\n",
    "                    ans = 2\n",
    "            else:\n",
    "                ans = 1\n",
    "        print(ans)\n",
    "    def testResult(self):\n",
    "        #\n",
    "        self.predict_list = []\n",
    "        self.now_list = []\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            for i in range(1,TEST_SIZE):\n",
    "                data = self.test_features_ts[i]\n",
    "                # resize\n",
    "                data = data.view(-1, SEQ_LENGTH, INPUT_SIZE).cuda()\n",
    "\n",
    "                # Forward pass\n",
    "                output = self.model(data.float()).item()\n",
    "\n",
    "                # restore output to normal value\n",
    "                output = output*(self.label_max-self.label_min)+self.label_min\n",
    "                self.predict_list.append(output)\n",
    "                now = self.test_labels[i]*(self.label_max-self.label_min)+self.label_min\n",
    "                self.now_list.append(now)\n",
    "                past = self.test_labels[i-1]*(self.label_max-self.label_min)+self.label_min\n",
    "                r1 = -1\n",
    "                r2 = -2\n",
    "                if((abs(output- past)/past) > 0.015):\n",
    "                    if(output >  past):\n",
    "                        #print('0', end = ',')\n",
    "                        r1 = 0\n",
    "                    else:\n",
    "                        #print('2', end = ',')\n",
    "                        r1 = 2\n",
    "                else:\n",
    "                    #print('1', end = ',')\n",
    "                    r1 = 1\n",
    "                if((abs(now-past)/past) > 0.015):\n",
    "                    if(now > past):\n",
    "                        #print('0')\n",
    "                        r2 = 0\n",
    "                    else:\n",
    "                        #print('2')\n",
    "                        r2 = 2\n",
    "                else:\n",
    "                    #print('1')\n",
    "                    r2 = 1\n",
    "                if(r2 == r1):\n",
    "                    correct += 1\n",
    "                #print(output, now, past,sep=',')\n",
    "            print(\"Accuracy: \", correct/(TEST_SIZE-1))\n",
    "        #\n",
    "        plt.plot(self.predict_list,label=\"predict\")\n",
    "        plt.plot(self.now_list,label=\"true\")\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "    def plotGraph(self):\n",
    "        plt.plot(self.train_loss_list,label=\"train\")\n",
    "        plt.plot(self.test_loss_list,label=\"test\")  \n",
    "        plt.title(\"Average Loss\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"MSE Loss\")\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_layers = NUM_LAYERS\n",
    "        self.hidden_size = HIDDEN_SIZE\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=HIDDEN_SIZE,\n",
    "            num_layers=NUM_LAYERS,\n",
    "            batch_first = True, # use batch size as first dimension, x -> (batch_size, seq, input_size)\n",
    "            dropout = DROP_OUT\n",
    "        )\n",
    "        self.fc = nn.Linear(HIDDEN_SIZE, 1) # fully connected\n",
    "\n",
    "    def forward(self, x ):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).cuda()\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).cuda()\n",
    "        \n",
    "        out, _ = self.lstm(x,(h0,c0))\n",
    "        out = out[:,-1,:]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb13080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.81568908691406 58.27999899999999, 1\n",
      "85.1189193725586 83.910004, 1\n",
      "51.08548355102539 51.459999, 1\n",
      "133.65750122070312 133.479996, 1\n",
      "85.66383361816406 88.059998, 2\n",
      "630.2608032226562 612.98999, 0\n",
      "138.94151306152344 142.679993, 2\n",
      "3428.6123046875 3471.310059, 1\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "NUM_FEATURES = 6\n",
    "TEST_SIZE = 1\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.005\n",
    "DROP_OUT = 0.0\n",
    "\n",
    "INPUT_SIZE = NUM_FEATURES # open, high, low, close, adj. close,volume\n",
    "SEQ_LENGTH = 14\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_LAYERS = 1\n",
    "FILE_NAME = ['INTC.csv','AMD.csv','CSCO.csv','AAPL.csv','MU.csv','NVDA.csv','QCOM.csv','AMZN.csv','NFLX.csv','FB.csv',\n",
    "             'GOOG.csv','BABA.csv','EBAY.csv','IBM.csv','XLNX.csv','TXN.csv','NOK.csv','TSLA.csv','MSFT.csv','SNPS.csv']\n",
    "\n",
    "# Preprocess\n",
    "for i in range(20):\n",
    "    sp1 = StockPrediction(FILE_NAME[i])\n",
    "    sp1.getFeatures()\n",
    "    sp1.getLabels()\n",
    "    sp1.shuffleData()\n",
    "    sp1.splitTrainTest(TEST_SIZE)\n",
    "    sp1.toTensor()\n",
    "    sp1.train()\n",
    "    #sp1.testResult()\n",
    "    #sp1.plotGraph()\n",
    "    sp1.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3680de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df71edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d27ba66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
